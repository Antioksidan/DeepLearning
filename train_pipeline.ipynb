{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696f8633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, utils\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "# custom dataloader\n",
    "from src.dataloader import DIV2KDataModule\n",
    "# Generator network\n",
    "from src.generator import Generator\n",
    "# Discriminator network\n",
    "from src.discriminator import Discriminator\n",
    "# module for VGG-based perceptual loss\n",
    "from src.vgg_wrapper import VGGLoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38bb509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataloader\n",
    "dataloader = DIV2KDataModule(batch_size=16, num_workers=4)\n",
    "dataloader.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3221739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# METRICS\n",
    "# =========================================================\n",
    "def psnr(pred, target, max_val=1.0):\n",
    "    mse = torch.mean((pred - target) ** 2).item()\n",
    "    if mse == 0:\n",
    "        return 99.0\n",
    "    return 10 * math.log10((max_val ** 2) / mse)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# TRAIN + EVAL\n",
    "# =========================================================\n",
    "def save_sample(sr_batch, epoch, out_dir=\"samples\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    # save first image in batch\n",
    "    img = sr_batch[0].detach().cpu()  # [3,H,W], in [0,1] thanks to Sigmoid\n",
    "    utils.save_image(img, os.path.join(out_dir, f\"sr_epoch_{epoch:03d}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f854377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_generator(G, train_loader, pretrain_epochs=10, lr=1e-4):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # pretrain generator (with mse)\n",
    "    print(\"Pretraining generator...\")\n",
    "\n",
    "    optim_G = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "    mse = nn.MSELoss()\n",
    "    mse.to(device)\n",
    "\n",
    "    for epoch in range(1, pretrain_epochs + 1):\n",
    "        G.train()\n",
    "        loop = tqdm.tqdm(train_loader, desc=f\"Pretrain Epoch {epoch}/{pretrain_epochs}\")\n",
    "        for lr_img, hr_img in loop:\n",
    "            lr_img = lr_img.to(device)\n",
    "            hr_img = hr_img.to(device)\n",
    "\n",
    "            optim_G.zero_grad()\n",
    "            sr_img = G(lr_img)\n",
    "\n",
    "            # perceptual = vgg_loss(sr_img, hr_img)\n",
    "            pixel_loss = mse(sr_img, hr_img)\n",
    "            pixel_loss.backward()\n",
    "            optim_G.step()\n",
    "\n",
    "            loop.set_postfix({\n",
    "                \"G\": f\"{pixel_loss.item():.4f}\",\n",
    "            })\n",
    "\n",
    "        # Save sample image from last batch\n",
    "        save_sample(sr_img, epoch, out_dir=\"pretrain_samples\")\n",
    "    \n",
    "    return G\n",
    "\n",
    "def train(G, D, train_loader, val_loader=None, num_epochs=50, lr=1e-4):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    vgg_loss = VGGLoss().to(device)\n",
    "    bce = nn.BCELoss().to(device)\n",
    "    mse = nn.MSELoss().to(device)\n",
    "\n",
    "    optim_G = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "    optim_D = torch.optim.Adam(D.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        G.train()\n",
    "        D.train()\n",
    "\n",
    "        loop = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs}\")\n",
    "        for lr_img, hr_img in loop:\n",
    "            lr_img = lr_img.to(device)\n",
    "            hr_img = hr_img.to(device)\n",
    "\n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            optim_D.zero_grad()\n",
    "\n",
    "            real_out = D(hr_img)\n",
    "            real_labels = torch.ones_like(real_out)\n",
    "            d_loss_real = bce(real_out, real_labels)\n",
    "\n",
    "            sr_img = G(lr_img).detach()\n",
    "            fake_out = D(sr_img)\n",
    "            fake_labels = torch.zeros_like(fake_out)\n",
    "            d_loss_fake = bce(fake_out, fake_labels)\n",
    "\n",
    "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "            d_loss.backward()\n",
    "            optim_D.step()\n",
    "\n",
    "            # ---------------------\n",
    "            # Train Generator\n",
    "            # ---------------------\n",
    "            optim_G.zero_grad()\n",
    "            sr_img = G(lr_img)\n",
    "\n",
    "            # adversarial loss - try to fool discriminator\n",
    "            pred_fake = D(sr_img)\n",
    "            adv_loss = bce(pred_fake, torch.ones_like(pred_fake))\n",
    "\n",
    "            # content losses\n",
    "            perceptual = vgg_loss(sr_img, hr_img)\n",
    "            pixel_loss = mse(sr_img, hr_img)\n",
    "\n",
    "            # combine (weights can be tuned)\n",
    "            g_loss = perceptual + 0.01 * pixel_loss + 1e-3 * adv_loss\n",
    "\n",
    "            g_loss.backward()\n",
    "            optim_G.step()\n",
    "\n",
    "            loop.set_postfix({\n",
    "                \"D\": f\"{d_loss.item():.4f}\",\n",
    "                \"G\": f\"{g_loss.item():.4f}\",\n",
    "            })\n",
    "\n",
    "        # Save sample image from last batch\n",
    "        save_sample(sr_img, epoch)\n",
    "\n",
    "        # ---------------------\n",
    "        # Validation PSNR\n",
    "        # ---------------------\n",
    "        if val_loader is not None:\n",
    "            G.eval()\n",
    "            with torch.no_grad():\n",
    "                psnr_vals = []\n",
    "                for lr_img, hr_img in val_loader:\n",
    "                    lr_img = lr_img.to(device)\n",
    "                    hr_img = hr_img.to(device)\n",
    "                    sr_img = G(lr_img)\n",
    "                    psnr_vals.append(psnr(sr_img, hr_img))\n",
    "                mean_psnr = sum(psnr_vals) / len(psnr_vals)\n",
    "                print(f\"Validation PSNR after epoch {epoch}: {mean_psnr:.2f} dB\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch}: validation skipped (no pairs).\")\n",
    "\n",
    "def save_models(G, D):\n",
    "    torch.save(G.state_dict(), \"generator_srgan.pth\")\n",
    "    torch.save(D.state_dict(), \"discriminator_srgan.pth\")\n",
    "    print(\"Models saved as generator_srgan.pth and discriminator_srgan.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aa3211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Pretraining generator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/1: 100%|██████████| 1224/1224 [20:20<00:00,  1.00it/s, G=0.0163]\n",
      "Epoch 1/5:   0%|          | 6/1224 [02:54<9:50:16, 29.08s/it, D=0.6434, G=7.8921]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 96\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     92\u001b[39m     g_loss.backward()\n\u001b[32m     93\u001b[39m     optim_G.step()\n\u001b[32m     95\u001b[39m     loop.set_postfix({\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43md_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     97\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mG\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg_loss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     98\u001b[39m     })\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Save sample image from last batch\u001b[39;00m\n\u001b[32m    101\u001b[39m save_sample(sr_img, epoch)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "SCALE_FACTOR = 4 # (64x64 -> 256x256)\n",
    "LR = 1e-4\n",
    "NUM_EPOCHS = 5\n",
    "GEN_PRETRAIN_NUM_EPOCHS = 1\n",
    "\n",
    "G = Generator(scale_factor=SCALE_FACTOR).to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "train_loader = dataloader.train_dataloader()\n",
    "val_loader = dataloader.val_dataloader()\n",
    "\n",
    "G = pretrain_generator(G, train_loader, pretrain_epochs=GEN_PRETRAIN_NUM_EPOCHS, lr=LR)\n",
    "G, D = train(G, D, train_loader, val_loader=val_loader, num_epochs=NUM_EPOCHS, lr=LR)\n",
    "save_models(G, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea424f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
